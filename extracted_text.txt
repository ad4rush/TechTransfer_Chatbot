=== Page 1 ===
SecurityVision: Real-Time Video Anomaly Detection using WatchTower and I3D
Features
KeshavChhabra AdarshJha KartikeyaMalik
IIITDelhi IIITDelhi IIITDelhi
keshav22247@iiitd.ac.in adarsh22024@iiitd.ac.in kartikeya22243@iiitd.ac.in
AkshatKothari
IIITDelhi
askhat22053@iiitd.ac.in
Abstract 2.RelatedWork
Automated surveillance systems are increasingly vi- Videoanomalydetection(VAD)researchhasexploredvar-
tal for public safety, requiring robust methods for de- ious approaches. Early methods often relied on trajectory
tecting anomalous events in real-time video feeds. This analysis or handcrafted features. Deep learning methods
project,”SecurityVision,”presentsasystemleveragingad- haveshownsignificantpromise.
vanced deep learning techniques for video anomaly de-
• FeatureModeling: ApproacheslikeSlowFastNetworks
tection. We utilize I3D features combined with a modi-
[6] analyze motion and appearance features at differ-
fied Self-Supervised Sparse Representation (WatchTower)
ent temporal speeds for action recognition, adaptable to
model, based on S3R. The system processes video input,
anomalydetection. I3D(Inflated3DConvNet)[1]effec-
identifies anomalous segments based on deviations from
tivelycapturesspatiotemporalinformationusing3Dcon-
learnednormalpatterns,andpresentsalertsandvisualiza-
volutionsandisacommonbackboneforVAD.
tions through a web-based dashboard. This report details
• Weakly-supervised VAD: Methods like the one pro-
theproblem,methodology,implementation,evaluation,and
posedbySultanietal. [2]utilizemultipleinstancelearn-
futuredirectionsoftheSecurityVisionsystem.
ing (MIL) to train models using only video-level labels
(normal/anomaly).
• Dictionary Learning for VAD: Recent works explore
1.ProblemStatement dictionary learning to model normality. S3R (Self-
Supervised Sparse Representation) [4], the basis for our
Overview: TheproliferationofCCTVsurveillanceneces- WatchTower model, learns a task-specific dictionary for
sitates automated systems capable of detecting unusual or normaleventsandusessparsityinreconstructiontoiden-
threateningactivities,suchasfights,assaults,orothersecu- tifyanomalies.ItemploysenNormalanddeNormalmod-
ritybreaches,whichoftengounnoticedinmanualmonitor- ules to separate and analyze normal/anomalous compo-
ing. AI-driven solutions are crucial for analyzing the vast nents. Linformer[3]providesamethodforefficientself-
amountofvideodatageneratedandprovidingtimelyalerts. attention with linear complexity, applicable for optimiz-
ingTransformer-basedcomponents.
ScopeoftheProblem:
• Input: Video feeds from CCTV cameras or uploaded Our work builds upon the strengths of feature modeling
videofiles. (I3D) and dictionary learning (S3R/WatchTower), poten-
• Output: Real-time or near-real-time identification of tiallyincorporatingLinformerforcomputationalefficiency.
anomalousvideosegments,anomalyscores,andalerts.
• User:Securitypersonnel,systemadministratorsmonitor-
ingsurveillancefeeds. 3.Methodology
• User Interface: A web-based dashboard for monitoring
feeds, visualizing detected anomalies, reviewing events, Oursystememploysapipelineapproachcombiningfeature
andmanagingalerts. extractionandaspecializedanomalydetectionmodel.


=== Page 2 ===
3.1.FeatureExtraction
We utilize pre-trained Inflated 3D ConvNet (I3D) models
[1], specifically variants with ResNet-50 backbones (e.g.,
‘i3d r50 kinetics.pth’),toextractrobustspatiotemporalfea-
tures(2048dimensions)frominputvideosegments. These
featurescaptureappearanceandmotioninformationcrucial
fordistinguishingnormalactivitiesfromanomalies.
3.2.AnomalyDetectionModel: WatchTower
WeadapttheSelf-SupervisedSparseRepresentation(S3R)
framework[4],whichwerefertoasWatchTowerinourim-
plementation, for anomaly detection. The core idea is to
learn a dictionary representing normal event patterns from
training data (UCF-Crime normal videos). Anomalies are
detectedasdeviationsthatcannotbesparselyreconstructed
usingthisdictionary.
KeyWatchTower(basedonS3R)componentsadaptedin
oursystem: Figure 1. Detailed architecture of the WatchTower anomaly de-
• Task-Specific Dictionary: A dictionary learned tection model. The layer-by-layer structure is based on the S3R
from normal video features (I3D) of the UCF- implementation.
Crime dataset using Orthogonal Matching Pur-
suit (OMP). The dictionary file used is ‘ucf-
crime dictionaries.taskaware.omp.100iters.50pct.npy‘. • AnomalyScoring: Frame-wiseROC-AUC(AreaUnder
• enNormalModule(potentiallywithLinformer): This theReceiverOperatingCharacteristicCurve)scoreisthe
module reconstructs the normal component of an input primary metric for evaluating anomaly detection perfor-
feature snippet using the learned dictionary. Efficiency manceondatasetslikeUCF-Crime.
improvementslikeLinformer-basedattentionmaybein-
corporated. 5.Implementation&UserInterface
• deNormal Module: This module aims to filter out the
ImplementationDetails:
normalcomponents,potentiallyhighlightingtheresidual
• Backend: PythonwithFlaskframework.
anomalousparts.
• MachineLearning: PyTorchformodelimplementation
• Anomaly Scoring: Features are passed through embed-
and inference (‘torch‘ 1.6.0, ‘torchvision‘). OpenCV
dinglayers(Aggregate, Dropout)andclassifiers. Thefi-
(‘opencv-python‘)forvideoprocessing. Keytrainingpa-
nalanomalyscoreforavideosegmentindicatesthelike-
rametersincludealearningrateof0.001anddropoutrate
lihoodofitbeinganomalous.
of0.7.
Themodelcheckpointusedis‘ucf-crime s3r i3d best.pth‘
• Models/Checkpoints: Uses pre-trained
(referredtoasWatchTowercheckpoint),trainedspecifically
I3D models (e.g.,‘i3d r50 kinetics.pth‘) and
forUCF-CrimeusingI3Dfeatures.
the WatchTower/S3R checkpoint (‘ucf-
The system processes video, extracts I3D features for
crime s3r i3d best.pth‘). A task-aware dictionary (‘ucf-
temporal segments, feeds features to the WatchTower
crime dictionaries.taskaware.omp.100iters.50pct.npy‘)is
model,calculatesanomalyscores,andpresentsresultsviaa
loaded.
webinterface.
• Dependencies: Key libraries include ‘numpy‘ (1.19.2),
‘PyYAML‘, ‘einops‘, ‘sqlalchemy‘. The training envi-
4.Datasets&EvaluationMetrics
ronmentutilizedCUDA10.1.
Dataset: UserInterfaceDesign:
• UCF-Crime [2]: A large-scale dataset containing long, • Web-basedDashboard:BuiltusingHTML,CSS(Boot-
untrimmed surveillance videos featuring 13 real-world strap), and JavaScript. Displays live feed (if camera ac-
anomalies (e.g., Fighting, Assault, Burglary, Explosion) cessisenabled),systemstatus,uptime,andrecentanoma-
andnormalactivities.Weusethestandardtraining/testing lies.
splits and I3D features provided alongside the S3R • Anomaly Visualization: When an anomaly is detected
methodologyfortrainingourWatchTowermodel. aboveathreshold(e.g.,0.6in‘ml model.py‘),visualand
EvaluationMetrics: audioalertsaretriggered.Areplayfeatureshowstheseg-

[Image page_2_image_0.png]
Gemini Response:
Certainly, let's analyze the provided image.

**Visual Elements:**

*   **Diagram Type:** The image is a flowchart-style diagram illustrating the architecture of the WatchTower anomaly detection model.
*   **Structure:** The diagram follows a hierarchical, top-down structure. It starts with input features and branches into processing modules.
*   **Shapes and Colors:** Boxes represent different layers or modules within the model. Colors differentiate module types, specified in a legend.
    *   Green represents a "Video Branch."
    *   Cyan represents a "Macro Branch."
    *   Yellow and orange represent "en/deNormal" blocks.
    *   Purple represents "Classifier" blocks.
    *   Pink represents "Dropout" layers.
*   **Arrows:** Arrows indicate the flow of data between modules.
*   **Layout:** The layout is generally symmetrical, with a split into "Video" and "Macro" branches early on, which later converge for classification.

**Textual Content:**

*   **Title:** "WatchTower Model Architecture" indicates the main subject.
*   **Input Features:** The process begins with "Input Features (2048)," suggesting a 2048-dimensional feature vector.
*   **Embedding Layers:**  "Video Embedding" and "Macro Embedding" include "Aggregate" modules described as combinations of 1D convolutions (Conv1d), Group Normalization (GN), and Rectified Linear Unit (ReLU) activation functions, along with non-local blocks.
*   **Dropout:**  "Dropout(p=0.7)" blocks indicating a regularization technique to prevent overfitting (with a dropout probability of 0.7).
*   **enNormal/deNormal Modules:** These appear to be central to the model:
    *   "enNormal" performs "Query, Cache, Value Embeddings (Linear Transformations)," referencing attention mechanisms.
    *   "deNormal" applies "Channel Attention (MLP: 2048->128->2048)," indicating a multi-layer perceptron (MLP) with specific layer sizes.
*   **Projection Layers:** "Video Projection" and "Macro Projection" are simple Conv1d + GN + ReLU blocks.
*   **Classification Layers:**  "Video Classifier" and "Macro Classifier" are linear layers followed by a Sigmoid or GlobalStatistics functions. The numbers indicate the layer dimensions (e.g., 2048 -> 512 -> 128 -> 1).
*   **Legend:** Clarifies the color-coding of the diagram elements.

**Contextual Significance:**

*   **Anomaly Detection:** The "WatchTower" name and module structure suggest an architecture designed for anomaly detection in video data.
*   **Feature Representation:** The model leverages video features (likely pre-extracted) for analysis. The I3D model is used for feature extraction and anomaly detection
*   **Macro/Video Branches:** The split into "Video" and "Macro" branches could represent separate processing paths for local and global video context, respectively.
*   **Attention Mechanisms:**  The "enNormal/deNormal" modules and the use of "Query, Cache, Value Embeddings" point to attention mechanisms to focus on relevant parts of the video for anomaly detection.
*   **Dictionary Learning :** The WatchTower Model is based on the S3R Framework which leverages task specific dictionary which is learned on the training data that consists of only normal videos
*   **Sparse Reconstruction:** The model detects anomalies as deviations that cannot be sparsely reconstructed using this dictionary.

In summary, the image provides a visual representation of the WatchTower anomaly detection model architecture, highlighting its key components, data flow, and design choices. The model uses a combination of convolutional layers, attention mechanisms, and classification layers to identify anomalies based on video features.


OCR Text:
WatchTower Model Architecture

Input Features (2048)
Video Embedding

Aggregate
cony_1-4: Convid + GN + ReLU

Legend
a Viteo Branch
Macro Branch

Macro Embedding enldeNornat

- Cassifors

oad

Aggregate
cony_1-4: Convid + GN + ReLU

Dropout

Gonv_S: Convid + GN+ReLU Gonv_S: Convid +GN+ReLU

rnon_local: NonLocalBlock1D rnon_local: NonLocalBlock1D

Dropout(p=0.7) Dropout(p=0.7)

enNormal

‘Query, Cache, Value Embeddings (Linear Transformations)

deNormal

Channel Attention (MLP: 2048-+128-+2048)

Video Projection Macro Projection
Convid + GN +ReLU Convid +GN+ReLU

Video Classifier Macro Classifier

Linear(2048-+512-+128-1) GlobalStatistics
‘Sigmoid Linear(2048-+512-+128-1)




=== Page 3 ===
mentleadinguptothealert. Table1.ReportedS3RPerformanceonUCF-Crime
• Controls: Userscanpause/resumesurveillance.
Dataset Method Feature AUC(%)
*Result
UCF-Crime S3R I3D 85.99
basedontheWatchTowerimplementationdetails[4].
Figure 4. Training loss curve for the WatchTower model on the
UCF-Crimedataset.
distinguishanomalousframesfromnormalframesinthe
Figure2.SecurityVisionWebInterface(DashboardView).
challengingUCF-Crimedataset.
• Theuseofdictionarylearningallowsthemodeltoeffec-
tivelycapturethemanifoldofnormalevents.
• Real-time performance depends on feature extraction
speed,modelinferencetime,andtheprocessingstrategy
(e.g., processingeveryNthframe). Furtheroptimization
might be needed for true real-time deployment on con-
strainedhardware.
7.ComputeRequirements
Training and deploying deep learning models for video
analysisrequiressignificantcomputationalresources.
• Training: Training the WatchTower model and po-
tentially the I3D feature extractor requires GPUs (e.g.,
NVIDIARTXseries)withsufficientmemory(e.g.,RTX
2080Tiusedinexperiments),especiallyforlargedatasets
Figure3.SecurityVisionWebInterface(AnomalyAlert). like UCF-Crime. Dictionary learning itself can also be
computationallyintensive.
• Inference: Real-time inference benefits greatly from
6.ResultsandAnalysis GPUacceleration. OurcurrentsystemchecksforCUDA
availability(testedwithCUDA10.1)andusesitifpossi-
TheS3Rmodel,uponwhichourWatchTowerimplementa- ble. CPUinferenceispossiblebutsignificantlyslower.
tionisbased,achievesstate-of-the-artorcompetitiveperfor- • Edge Computing: For deployment on edge devices,
manceonstandardvideoanomalydetectionbenchmarks. model optimization techniques like quantization and
Performance on UCF-Crime: The S3R methodology hardware acceleration are crucial but need careful eval-
usingI3Dfeaturesreportsaframe-levelAUCof85.99%on uation.
the UCF-Crime dataset [4]. Our WatchTower model aims • Memory/Storage: Handling video streams and fea-
toreplicateorbuilduponthisperformance. turesrequiresadequateRAMandpotentiallyfaststorage
Observations: (SSDs).
• The reported AUC of ∼86% indicates a strong capabil- • Software Environment: The system relies on Python
ity of the S3R/WatchTower model with I3D features to (3.6tested),PyTorch(1.6.0tested),Flask,andassociated

[Image page_3_image_0.png]
Gemini Response:
Here's a thorough analysis of the image:

**Visual Elements:**

*   **Color Scheme:** The image uses a dark, predominantly purple and blue color scheme, creating a modern and security-oriented aesthetic.
*   **Iconography:** A large camera icon in a purple tone is the central visual element, emphasizing the system's video surveillance purpose. Small icons are used to represent different sections (anomalies, activity, status, information).
*   **Layout:** The layout is clean and organized, with clear sections and visual hierarchies. Information is presented in cards or tiles for easy readability. A "Start" button is prominently placed.
*   **Fonts:** The image uses clean, sans-serif fonts, contributing to the modern design.
*   **Emphasis/Hierarchy:** Larger font sizes and bolder text are used to highlight key information (e.g., "Security," "31", the status "Ready", the date).

**Text Content:**

*   **Header:** "Video Surveillance" is the top-level branding or application name.
*   **Navigation:** "Dashboard" and "Surveillance" act as navigation links.
*   **Central Title:** "Security," followed by "Advanced anomaly detection," clearly states the system's function.
*   **Button:** "Start" indicates the action to initiate the surveillance process.
*   **Anomalies Detected:** "31" is displayed as the total number of anomalies.
*   **Last Activity:** Displays the date and time of the most recent anomaly: "2025-04-22 23:02:05."
*   **Status:** "Ready" indicates the system's operational state.
*   **Information:**
    *   **AI Model:** "Using WatchTower model for anomaly detection."  "Based on UCF-Crime dataset pretraining with advanced feature extraction capabilities." Describes the underlying AI algorithm.
    *   **System Capabilities:** A bulleted list details the system's features:
        *   Real-time video analysis
        *   Sparse representation for anomaly detection
        *   Automatic alarm system on detection
        *   Backward-timer for anomaly review
*   **Footer:** "Video Surveillance System © 2025" indicates copyright information and system ownership.

**Contextual Significance:**

*   **Surveillance System Interface:** The image is a screenshot of a user interface (UI) for a video surveillance system that uses AI to detect anomalies.
*   **Anomaly Detection:** The emphasis on "Advanced anomaly detection" and the display of the number of detected anomalies highlight the core functionality of the system.
*   **Real-time Monitoring:** The "Ready" status and the system capabilities suggest real-time or near real-time monitoring.
*   **WatchTower Model:** The mention of the "WatchTower model" indicates a specific algorithm or AI model used for anomaly detection.
*   **UCF-Crime Dataset:** The reference to the "UCF-Crime dataset" points to a specific dataset used for training and validating the AI model, implying its focus on detecting criminal activities.

**In summary:** The image presents a clean, modern UI for a video surveillance system. Its key features include real-time anomaly detection using the WatchTower model, pre-trained on the UCF-Crime dataset.  The UI aims for ease of use and provides clear visual indicators of system status and detected anomalies.


OCR Text:
= Ser fe Dashboard Me Surveillance

OnE Bons
2025-04-2223:02:05 © Ready
31 ves ent ancray we
“taaomaes
@ Information
acters ‘%q System Capabilities
sng stowed for nol etecton Oe
eased on UCF-Crime dataset retaining wth advanced feature extraction nee a
1 Sackardsimefronomaly row

wae Sunetaes Stan ©2025



[Image page_3_image_1.png]
Gemini Response:
Here's a breakdown of the image, based on your provided OCR and visual analysis:

**Visual Elements:**

*   **Color Scheme:** The interface has a dark color scheme, likely to be easy on the eyes and to ensure the most important content is the most visible.

*   **Layout:** The UI appears to be divided into sections or panes, arranged in a grid.

*   **Icons:** The design incorporates icons to represent different statuses and functions (e.g., status, uptime, live feed, recent anomalies).
*   **Graphical Indicators:** The monitoring status utilizes a green checkmark to denote that no anomalies have been detected, visually confirming the system's state.

*   **"Camera Not Available" Overlay:**  A large icon (camera crossed out) indicates that the live feed isn't currently active or accessible.

**Text Content:**

*   **Title:** "Video Surveillance" and "Surveillance Mode" indicate that this is a display for monitoring surveillance systems.

*   **Status Indicators:**

    *   "Frames Processed: 2" -  Shows the number of frames processed by the surveillance system.

    *   "Uptime: 00:00:10" - Indicates the system's running time, in hours, minutes, and seconds.

    *   "Monitoring Status: No anomalies detected" -  Confirms that the system isn't currently flagging any events as anomalous.

*   **Live Feed:** "Live Feed" indicates where a camera feed should be displayed. "Camera not available" message and "Start Camera" button suggest that the camera is offline or needs to be activated.
*   **Anomalies:** "Recent Anomalies: No anomalies recorded yet" -  Indicates no unusual events have been detected and recorded in the system.

*   **Control Buttons:** "Resume Surveillance" and "Dashboard" are buttons that offer user interaction. Surveillance Paused text shows that the surveillance is paused, suggesting that these functionalities are available to control the system.

**Contextual Significance:**

*   **Surveillance System Dashboard:** This is a web interface designed for real-time monitoring and control of a video surveillance system.
*   **Anomaly Detection:** The UI indicates a focus on anomaly detection within the video feeds. The "No anomalies detected" and "Recent Anomalies" sections are crucial for this functionality.
*   **System Status:** The "Status," "Uptime," and "Monitoring Status" sections provide essential information about the health and operational state of the surveillance system.
*   **User Interaction:** The "Start Camera" and "Resume Surveillance" buttons provide the user with the ability to control the surveillance process.
*   **Paused State:** The UI's state appears to be in a paused or inactive mode, given the "Surveillance Paused" indicator and the "Camera Not Available" message. The "Resume Surveillance" button is visible, prompting the user to re-enable the live feed and anomaly detection.


OCR Text:
“® Video Surveillance f¥ Dashboard me Surveillance

Surveillance Mode © set roe

© status © Uptime © Monitoring Status
2 00:00:10 i)
Frames Processed ‘System running time
‘No anomalies detected
@ Live Feed 'D Recent Anomalies

No anomalies recorded yet

Camera not available

‘Start Camera



[Image page_3_image_2.png]
Gemini Response:
Here's a detailed but concise analysis of the image:

**Visual Elements:**

*   **Chart Type:** Line graph (scatter plot with lines)
*   **Line Color:** Blue
*   **Background:** White with a light gray grid for easier reading of values.
*   **Markers:** Blue circles indicating data points along the line.

**Text Content:**

*   **Title:** "Training Loss vs. Step" indicating the relationship being visualized.
*   **X-Axis Label:** "Step" - Represents the iteration or step number in the training process. Values are 0, 500, 1000, 1500, 2000, 2500, and 3000.
*   **Y-Axis Label:** "Training Loss" - Represents the loss value during training. Values are shown from 0.4 to 1.8 with increments of 0.2.

**Contextual Significance:**

*   **Purpose:** The graph illustrates the training performance of a machine learning model over time (steps). Specifically, it shows how the training loss decreases as the model learns.
*   **Interpretation:**
    *   The loss decreases rapidly in the initial steps, indicating fast learning.
    *   The loss continues to decrease, with some fluctuations, and then it flattens out, indicating that the model is gradually learning less with each step.
    *   The near-flatness in later steps suggests that the model might be approaching convergence or reaching a point where further training yields diminishing returns.

OCR Text:
1.8

1.6

1.4

1.2

Training Loss

0.8

0.6

0.4

Training Loss vs. Step

500

1000

1500
Step

2000

2500

3000



=== Page 4 ===
libraries. 10.CodeRepository
While initial development might be feasible on moder-
The source code for this project is available
ate hardware, scaling up for robust real-time deployment
on GitHub: https : / / github . com / kv -
across multiple streams likely necessitates more powerful
248/SecurityVision
resources.
References
8.IndividualTasks
[1] Joao Carreira and Andrew Zisserman. Quo vadis, action
recognition? anewmodelandthekineticsdataset. InPro-
ceedings of the IEEE Conference on Computer Vision and
Table2.TeamMemberResponsibilities
PatternRecognition(CVPR),pages6299–6308,2017. 2,3
[2] WaqasSultani,ChenChen,andMubarakShah. Real-world
TeamMember AssignedTasks
anomaly detection in surveillance videos. In Proceedings
KeshavChhabra Data preprocessing, model of the IEEE Conference on Computer Vision and Pattern
training (WatchTower/S3R Recognition(CVPR),pages6479–6488,2018. 2,3
adaptation),evaluation. [3] SinongWang,BelindaZ.Li,MadianKhabsa,HanFang,and
KartikeyaMalik User interface design HaoMa. Linformer: Self-attentionwithlinearcomplexity.
arXivpreprintarXiv:2006.04768,2020. 2
(Flask/HTML/JS), API in-
[4] Jhih-CiangWu,He-YenHsieh,Ding-JieChen,Chiou-Shann
tegration,deploymentsetup.
Fuh,andTyng-LuhLiu.Self-SupervisedSparseRepresenta-
AdarshJha Model training (Watch-
tionforVideoAnomalyDetection. InEuropeanConference
Tower/S3R adaptation),
onComputerVision(ECCV),pages105–121,2022. 2,3,4
Linformer integration anal-
[5] Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K.
ysis,evaluation.
Roy-Chowdhury,andLarryS.Davis.Learningtemporalreg-
AkshatKothari Dataset handling (UCF-Crime
ularityinvideosequences. InProceedingsoftheIEEEcon-
features), documentation, per- ferenceoncomputervisionandpatternrecognition(CVPR),
formance analysis, results re- pages733–742,2016.
porting. [6] Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and
Kaiming He. Slowfast networks for video recognition. In
Proceedings of the IEEE/CVF international conference on
computervision(ICCV),pages6202–6211,2019. 2
9.FutureWork [7] SachinMehtaandMohammadRastegari. Mobilevit: light-
weight, general-purpose, and mobile-friendly vision trans-
Building upon the current SecurityVision system utilizing former. arXivpreprintarXiv:2110.02178,2021. 5
WatchTower with I3D features, future work can focus on [8] WenjuCai, MichaelB.Zaremba, AshtonB.Thickstun, Ja-
severalareas: son Kuen, Richard T. Chen, Kuan-Hui Lee, Ga´bor Barto´k,
Duncan T. Howcroft, Ashok Ravichandran, and Stephan
1. Explore more efficient feature extractors: I3D hap- Mandt. Lifelong anomaly detection via rehearsal-aided
pens to be a computationally heavy model. Exploring pseudo-residuallearning. arXivpreprintarXiv:2306.04195,
alternativeslikeMobileViT[7]couldofferbetterperfor- 2023. 5
mance/cost trade-offs, potentially enabling edge-device [9] ZilongZhang,ZhongdaoLiu,ChenChangeLoy,andDahua
inference. Lin. Cross-viewactionrecognitionviaviewpointdecompo-
2. Onlinelearning: Sincethedictionaryrepresentingnor- sitionandrecovery.InProceedingsoftheIEEE/CVFConfer-
enceonComputerVisionandPatternRecognition(CVPR),
malityisbuiltoffline,implementingonlineorcontinual
pages7084–7093,2019. 5
learning approaches [8] could allow the model to adapt
to specific deployment environments and evolving nor-
malpatternsovertime.
3. Multiple Cameras: Utilizing synchronized feeds from
multiplecamerasviamulti-viewlearningtechniques[9]
could provide richer context, handle occlusions better,
andpotentiallyincreasedetectionrobustness.
Byaddressingthesepoints,weaimtoenhanceSecurityVi-
sion into a more robust, efficient, and versatile real-time
anomalydetectionsystemsuitableforpracticalsurveillance
applications.


=== Page 5 ===
A.TimingAnalysisScreenshots
(a)Beforeoptimization (b)Afteroptimization
Figure 5. Component-wise timing analysis of our inference
pipeline.
B.Systemarchitecture
Figure6.Systemarchitecture

[Image page_5_image_0.png]
Gemini Response:
Here's a breakdown of the image's content, visual elements, and context within the surrounding text:

**Visual Elements:**

*   The image shows text displayed in a code-like or terminal-like format. The background is dark, and the text is in a monospaced font.
*   The presentation resembles output from a program, likely capturing timing metrics.

**Text Content:**

The image contains the following text:

*   `--- Timing Analysis (seconds) ---` This line indicates that the subsequent information is a breakdown of the time spent in different parts of a process, measured in seconds.
*   `enNormal: 0.962678` This likely refers to the time taken by the "enNormal" module, which the surrounding document describes as reconstructing the normal component of the input feature snippet.
*   `video_embedding: 0.053841`  This likely measures the time it takes to generate the video embedding.
*   `macro_embedding: 0.027548` This is the timing for generating macro embeddings.
*   `deNormal: 0.001727` This refers to the time taken by the "deNormal" module, which aims to filter out the normal components of the video data.
*   `classifier: 0.009585` This measures the time the classification model takes.
*   `total_inference: 1.085437`  This represents the total time spent on the entire inference process.

**Contextual Significance (within the surrounding text):**

*   The image is referenced in Figure 5 of the document, titled "Component-wise timing analysis of our inference pipeline."
*   The image and its surrounding description are found in Section A, titled "Timing Analysis Screenshots." This section likely presents screenshots comparing timing data before and after optimizations.
*   The `enNormal` and `deNormal` components are related to the "WatchTower" anomaly detection model, which the document describes as an adaptation of the S3R (Self-Supervised Sparse Representation) framework. WatchTower uses dictionary learning to model normal event patterns.
*   The document discusses optimizing the pipeline, potentially using techniques like Linformer for efficiency. The image likely represents the timings *before* optimization, since there is a mention of (a) Before Optimization in A.TimingAnalysisScreenshots

In summary, the image visualizes the timing performance of various modules within the anomaly detection inference pipeline. The surrounding document analyzes and presents the performance of the "SecurityVision" system, which uses deep learning techniques for video anomaly detection.


OCR Text:
--- Timing Analysis (seconds) ---
enNormal: @.962678

video embedding: 9.053841
macro_embedding: 0.027548
deNormal: @.001727

classifier: 0.009585

total inference: 1.085437




[Image page_5_image_1.png]
Gemini Response:
Here's a detailed analysis of the image based on the provided context and OCR output:

**Visual Elements:**

*   The image appears to be a screenshot of text output, likely from a terminal or console window.
*   The background is a dark color, typical of code editors or terminal interfaces.
*   The text is displayed in a light color, providing contrast.
*   There is a dashed line at the top and bottom of the text block, possibly indicating the start and end of a log or analysis section.

**Text Content:**

The OCR output reveals the following information:

*   `--- Timing Analysis (seconds) ---`: This indicates the data presented is related to the timing performance of a system, measured in seconds.
*   `enNormal: 0.814171`: The 'enNormal' module or process took 0.814171 seconds. This might refer to the "enNormal" module which reconstructs the normal component of a video according to the research paper described in the whole context.
*   `video_embedding: 0.067756`: The 'video embedding' process (likely extracting video features) took 0.067756 seconds.
*   `macro_embedding: 0.019474`: The `macro_embedding` process took 0.019474 seconds.
*   `deNormal: 0.001290`: The 'deNormal' module or process took 0.001290 seconds. This might refer to the "deNormal" module which filters out the normal components according to the research paper described in the whole context.
*   `classifier: 0.001736`: The classification step took 0.001736 seconds.
*   `total_inference: 0.905373`: The total inference time for the entire process was 0.905373 seconds.

**Contextual Significance:**

*   **Part of Anomaly Detection System:** Based on the broader document ("SecurityVision: Real-Time Video Anomaly Detection..."), this image shows a timing analysis of the inference pipeline for the system.
*   **Performance Analysis:** This data likely comes from Figure 5 ("Component-wise timing analysis of our inference pipeline.") mentioned in the document. This figure shows timing performance of the anomaly detection model before and after optimization.
*   **Profiling:** The timing analysis data provides insights into the performance bottlenecks of the system. For example, 'enNormal' takes the most time, which is important when the authors want to analyze how to optimize their model in the next step.
*   **Optimization Comparison:**  The image is probably paired with another screenshot in Figure 5 showing the timing after optimization to demonstrate the effectiveness of any optimizations implemented.

In summary, the image shows the timing analysis of the components within an anomaly detection system for videos. This timing data is crucial for identifying performance bottlenecks and evaluating optimization efforts.


OCR Text:
--- Timing Analysis (seconds) ---
enNormal: @.814171

video embedding: 0.067756
macro_embedding: 0.019474
deNormal: @.001290

classifier: 0.001736
total_inference: 9.905373




[Image page_5_image_2.jpeg]
Gemini Response:
Here's a concise analysis of the image, combining visual and textual elements:

**Visual Elements:**

*   **Diagram:** The image is a flowchart representing a video processing pipeline for anomaly detection.
*   **Shapes:** Rectangles, diamonds, and arrows illustrate the sequence of operations.
*   **Color Coding:** Colors are used to categorize different stages of processing, e.g., initial video input (blue), frame processing (green and yellow), feature extraction and anomaly detection (purple), alert actions (red) and the final step of Dashboard Review (blue).
*   **Arrows:** Arrows indicate the flow and direction of the video stream and data processing.

**Text Content and Flow:**

The flowchart outlines the following steps:

1.  **CCTV Camera Video Stream:** Input from a surveillance camera.
2.  **Video Input Layer:** Indicates the input processing layer.
3.  **Frame Extraction with Canvas:** Frames are extracted from the video using a canvas, implying potential image manipulation or processing at this stage.
4.  **Send Frame to Backend via HTTP POST:** Frames are transmitted to a backend server.
5.  **Frame Buffering:** Frames are stored temporarily.
6.  **Preprocessing Resize and Normalize:** Frames are resized and normalized to prepare them for feature extraction.
7.  **Feature Extraction using I3D or others:** Spatial-temporal features are extracted using a method like I3D.
8.  **Anomaly Detection:** Anomalies are detected based on the extracted features.
9.  **Anomaly Detected?:** A conditional check determines if an anomaly is present.
    *   **Yes:** If an anomaly is detected, actions are taken:
        *   "Trigger Alert in UI" - A notification is displayed in the user interface.
        *   "Store Snippet and Save to DB" - The video segment and related data are saved to a database.
    *   **No:** If no anomaly is detected, "Process Next Frame".
10. **Dashboard for Review:** All these streams converge to the review dashboard.

**Contextual Significance:**

*   The diagram illustrates a real-time video anomaly detection system.
*   It leverages deep learning (I3D) to extract features, suggesting a data-driven approach.
*   The architecture shows a separation between the front-end (UI, alerts) and back-end (processing, database).
*   The process allows for automated monitoring and alert generation for potential security breaches.
*   The flow is structured to enable timely responses to identified anomalous events, enhancing surveillance capabilities.


OCR Text:
CCTV Camera Video Stream

Feature Extraction using 3D or
others

Process Next Frame



